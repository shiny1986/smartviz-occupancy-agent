import os
import sqlite3
import json
import pandas as pd

from dotenv import load_dotenv
load_dotenv()
gemini_api_key = os.getenv("GEMINI_API_KEY")

DB_PATH = os.path.join(os.path.dirname(__file__),'Smartviz.db')

from langchain_google_genai import ChatGoogleGenerativeAI
llm = ChatGoogleGenerativeAI(model = "gemini-2.5-flash",api_key = gemini_api_key,temperature=0.0)

from typing import Annotated,TypedDict,Sequence
from langchain_core.messages import BaseMessage,HumanMessage,AIMessage,SystemMessage
from langgraph.graph.message import add_messages
from langchain_core.tools import tool
from langgraph.graph import StateGraph,END

# Tool definition
@tool
def sql_query(query:str)->str:
    """
    Executes a read-only SQL query against the METRICS table in the Smartviz.db SQLite database.
    """
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute(query)
        results = cursor.fetchall()
        return str(results)
    except Exception as e:
        return f"Database Error:{e}"
    finally:
        if conn:
            conn.close()

# State definition
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage],add_messages]
    query_result: str
    chart_config: dict

# Nodes
def run_query_agent(state: AgentState):
    """Node 1: Generates SQL. Includes specific instructions for column naming and comparisons."""
    system_prompt = (
        "You are an expert SQL generator for SQLite. The table is METRICS."
        "STRICT COLUMN NAMES (Use these exactly):"
        "- Value column: `_v_a_l_u_e_` (Always use CAST(_v_a_l_u_e_ as REAL))."
        "- Time column: `_s_t_a_r_t___t_i_m_e_` (FORMAT: 'YYYY-MM-DD HH:MM:SS.000 +0000')."
        "- Metric Name column: `_m_e_t_r_i_c___n_a_m_e_` (Note the triple underscores between words)."
        "RULES:"
        "1. Filter for Metric: 'Occupancy'."
        "2. Skip the header row: `WHERE _s_t_a_r_t___t_i_m_e_ != 'start_time'`."
        "3. For comparisons, use UNION ALL to retrieve results for both periods in one result set."
        )
    full_messages = [SystemMessage(content=system_prompt)] + list(state["messages"])
    query_agent = llm.bind_tools([sql_query])
    result = query_agent.invoke(full_messages)
    return {"messages":[result]}

def execute_sql(state: AgentState):
    """Node 2: Executes the tool call generated by the query agent."""
    last_message = state["messages"][-1]
    if not last_message.tool_calls:
        return state
    query = last_message.tool_calls[0]["args"]["query"]
    print(f"\n[SQL generated]:{query}")
    raw_result = sql_query.invoke(query)
    print(f"\n[Raw result]:{raw_result}")
    return {"query_result":raw_result}

def run_visualization_agent(state: AgentState):
    """Translates DB results into a JSON configuration for a chart."""
    if not state["query_result"] or "Database Error" in state["query_result"] or state["query_result"] == "[]":
        return {"chart_config": {"type":"none"}}
    vis_prompt = (
        f"Data from Database: {state['query_result']}\n"
        f"User Question: {state['messages'][0].content}\n"
        "Create a chart plan. Return ONLY a raw JSON object string with no backticks:"
        '{"type": "bar", "title": "Comparison", "labels": ["A","B"], "values": [10,20]}'
    )
    try:
        response = llm.invoke(vis_prompt)
        content = response.content.strip()
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        config = json.loads(content)
        print(f"[CHART JSON]: {json.dumps(config,indent=2)}")
        return {"chart_config": config}
    except Exception as e:
        print(f"Visualization Error: {e}")
        return {"chart_config": {"type": "none"}}

def run_analysis_agent(state: AgentState):
    """Node 4: Provides a natural language explanation, referencing the chart if it exists."""
    msg = f"Data: {state['query_result']}\nQuestion: {state['messages'][0].content}\n"
    if state["chart_config"].get("type") != "none":
        msg += f"(Note: A {state['chart_config']['type']} chart has been prepared.)"
    analysis_message = llm.invoke(msg)
    return {"messages": [analysis_message]}

# Router
def router(state: AgentState):
    """Decides the path of the workflow."""
    if state.get("query_result"):
        return "visualize"
    if state["messages"][-1].tool_calls:
        return "execute_sql"
    return END     

# Graph
workflow = StateGraph(AgentState)
workflow.add_node("query_agent",run_query_agent)
workflow.add_node("execute_sql",execute_sql)
workflow.add_node("visualize",run_visualization_agent)
workflow.add_node("analyze",run_analysis_agent)
workflow.set_entry_point("query_agent")
workflow.add_conditional_edges("query_agent",router,{"execute_sql": "execute_sql", END:END})
workflow.add_edge("execute_sql","visualize")
workflow.add_edge("visualize","analyze")
workflow.add_edge("analyze",END)
app = workflow.compile()

# --- 6. STANDALONE TESTING ---
if __name__ == "__main__":
    test_question = "What was the total occupancy for the morning of 2025-03-01?"
    print(f"\n>>> TESTING QUERY: {test_question}")
    print("-" * 50)
    
    initial_state = {"messages": [HumanMessage(content=test_question)], "query_result": "", "chart_config": {}}
    final_output = app_engine.invoke(initial_state)
    
    print(f"\n[FINAL RESPONSE]:\n{final_output['messages'][-1].content}")
    print(f"\n[CHART JSON]: {json.dumps(final_output['chart_config'], indent=2)}")